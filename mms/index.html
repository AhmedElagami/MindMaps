<!doctype html>
<html>
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<meta http-equiv="X-UA-Compatible" content="ie=edge" />
<title>Markmap</title>
<style>
* {
  margin: 0;
  padding: 0;
}
html {
  font-family: ui-sans-serif, system-ui, sans-serif, 'Apple Color Emoji',
    'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
.markmap-dark {
  background: #27272a;
  color: white;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.18/dist/katex.min.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.9.0/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.18.12/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.18.12/dist/index.js"></script><script>((getMarkmap) => {
          window.WebFontConfig = {
            custom: {
              families: [
                "KaTeX_AMS",
                "KaTeX_Caligraphic:n4,n7",
                "KaTeX_Fraktur:n4,n7",
                "KaTeX_Main:n4,n7,i4,i7",
                "KaTeX_Math:i4,i7",
                "KaTeX_Script",
                "KaTeX_SansSerif:n4,n7,i4",
                "KaTeX_Size1",
                "KaTeX_Size2",
                "KaTeX_Size3",
                "KaTeX_Size4",
                "KaTeX_Typewriter"
              ]
            },
            active: () => {
              getMarkmap().refreshHook.call();
            }
          };
        })(() => window.markmap)</script><script src="https://cdn.jsdelivr.net/npm/webfontloader@1.6.28/webfontloader.js" defer></script><script>(r => {
              setTimeout(r);
            })(function renderToolbar() {
  const {
    markmap,
    mm
  } = window;
  const {
    el
  } = markmap.Toolbar.create(mm);
  el.setAttribute('style', 'position:absolute;bottom:20px;right:20px');
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
              const markmap = getMarkmap();
              window.mm = markmap.Markmap.create(
                "svg#mindmap",
                (getOptions || markmap.deriveOptions)(jsonOptions),
                root2
              );
              if (window.matchMedia("(prefers-color-scheme: dark)").matches) {
                document.documentElement.classList.add("markmap-dark");
              }
            })(() => window.markmap,null,{"content":"MMAS","children":[{"content":"Agents","children":[{"content":"Agent Paradigms","children":[{"content":"Post-Declarative System <strong>(~GI)</strong>","children":[{"content":"<strong>High-Level Goal Focus</strong>","children":[{"content":"Specifies what to achieve rather than how, leaving agents to determine the steps using their autonomy and reasoning.","children":[],"payload":{"tag":"li","lines":"6,7"}}],"payload":{"tag":"h5","lines":"5,6"}},{"content":"<strong>Interaction-Based Behavior</strong>","children":[{"content":"Agents develop behavior through interactions with data and the environment, rather than relying solely on predefined rules.","children":[],"payload":{"tag":"li","lines":"8,9"}}],"payload":{"tag":"h5","lines":"7,8"}},{"content":"Vs Other Systems","children":[{"content":"<strong>Procedural</strong>","children":[{"content":"Specifies exact steps to follow in a &quot;do this, then that&quot; manner.","children":[],"payload":{"tag":"li","lines":"11,12"}}],"payload":{"tag":"h6","lines":"10,11"}},{"content":"<strong>Declarative</strong>","children":[{"content":"Defines the goal and relationships, leaving the system to determine how to achieve it.","children":[],"payload":{"tag":"li","lines":"13,15"}}],"payload":{"tag":"h6","lines":"12,13"}}],"payload":{"tag":"h5","lines":"9,10"}}],"payload":{"tag":"h4","lines":"4,5"}},{"content":"Intentional System <strong>(~ICU)</strong>","children":[{"content":"<strong>Intentional Stance</strong>","children":[{"content":"Treating the system as having beliefs, desires, and intentions aids in predicting and interpreting its actions.","children":[],"payload":{"tag":"li","lines":"17,18"}}],"payload":{"tag":"h5","lines":"16,17"}},{"content":"<strong>Compact Expression</strong>","children":[{"content":"Mental-like concepts such as goals and beliefs provide concise explanations for system behavior.","children":[],"payload":{"tag":"li","lines":"19,20"}}],"payload":{"tag":"h5","lines":"18,19"}},{"content":"<strong>Understanding Structure and Behavior</strong>","children":[{"content":"Enables explanation and potential improvement of the system&#x2019;s functioning.","children":[],"payload":{"tag":"li","lines":"21,23"}}],"payload":{"tag":"h5","lines":"20,21"}}],"payload":{"tag":"h4","lines":"15,16"}},{"content":"Agents Comparisons","children":[{"content":"Vs Objects <strong>(~AIA)</strong>","children":[{"content":"<strong>Autonomy</strong>","children":[{"content":"Unlike objects that execute commands when called, agents can choose or refuse actions based on their internal state.","children":[],"payload":{"tag":"li","lines":"26,27"}}],"payload":{"tag":"h6","lines":"25,26"}},{"content":"<strong>Intelligence</strong>","children":[{"content":"Objects are passive and lack reasoning, whereas agents exhibit smart, adaptable behavior.","children":[],"payload":{"tag":"li","lines":"28,29"}}],"payload":{"tag":"h6","lines":"27,28"}},{"content":"<strong>Activeness</strong>","children":[{"content":"Objects remain idle until invoked, while agents actively initiate their own actions.","children":[],"payload":{"tag":"li","lines":"30,31"}}],"payload":{"tag":"h6","lines":"29,30"}}],"payload":{"tag":"h5","lines":"24,25"}},{"content":"Vs Expert Systems <strong>(~EAO)</strong>","children":[{"content":"<strong>Environment Awareness</strong>","children":[{"content":"Agents perceive and act within their environment, while expert systems rely solely on input data.","children":[],"payload":{"tag":"li","lines":"33,34"}}],"payload":{"tag":"h6","lines":"32,33"}},{"content":"<strong>Action Capability</strong>","children":[{"content":"Agents can execute actions, whereas expert systems mainly offer advice or conclusions.","children":[],"payload":{"tag":"li","lines":"35,36"}}],"payload":{"tag":"h6","lines":"34,35"}},{"content":"<strong>Overlap</strong>","children":[{"content":"Some advanced expert systems function like agents, but this is not universally true.","children":[],"payload":{"tag":"li","lines":"37,38"}}],"payload":{"tag":"h6","lines":"36,37"}}],"payload":{"tag":"h5","lines":"31,32"}}],"payload":{"tag":"h4","lines":"23,24"}}],"payload":{"tag":"h3","lines":"3,4"}},{"content":"Agent Properties <strong>(~RPS)</strong>","children":[{"content":"<strong>Reactivity</strong>","children":[{"content":"Agents continuously sense and respond to environmental changes.","children":[],"payload":{"tag":"li","lines":"40,41"}}],"payload":{"tag":"h4","lines":"39,40"}},{"content":"<strong>Proactivity</strong>","children":[{"content":"Agents are driven by goals and proactively take actions to achieve them.","children":[],"payload":{"tag":"li","lines":"42,43"}}],"payload":{"tag":"h4","lines":"41,42"}},{"content":"<strong>Social Ability</strong>","children":[{"content":"Agents interact with others through cooperation, coordination, and negotiation to fulfill tasks.","children":[],"payload":{"tag":"li","lines":"44,45"}}],"payload":{"tag":"h4","lines":"43,44"}}],"payload":{"tag":"h3","lines":"38,39"}},{"content":"Agent Architecture","children":[{"content":"Definition (~<code>Perceives, Processes, Remembers, and Acts</code>)","children":[{"content":"Agent architecture is the <strong>underlying structure</strong> of an agent system.","children":[],"payload":{"tag":"li","lines":"47,48"}},{"content":"It defines how an agent:","children":[{"content":"<strong>Perceives</strong> its environment.","children":[],"payload":{"tag":"li","lines":"49,50"}},{"content":"<strong>Processes</strong> information.","children":[],"payload":{"tag":"li","lines":"50,51"}},{"content":"<strong>Maintains</strong> internal state.","children":[],"payload":{"tag":"li","lines":"51,52"}},{"content":"<strong>Selects</strong> actions.","children":[],"payload":{"tag":"li","lines":"52,54"}}],"payload":{"tag":"li","lines":"48,54"}}],"payload":{"tag":"h4","lines":"46,47"}},{"content":"Main Architectures (~ <code>Really Powerful Systems Act Using Optimal Balance</code>)","children":[{"content":"<strong>Purely Reactive Agents</strong>: Respond directly to stimuli without memory or reasoning.","children":[],"payload":{"tag":"li","lines":"55,56"}},{"content":"<strong>Agents with Perception Ability</strong>: Can detect and interpret environmental inputs.","children":[],"payload":{"tag":"li","lines":"56,57"}},{"content":"<strong>Agents with State</strong>: Maintain internal data about past interactions.","children":[],"payload":{"tag":"li","lines":"57,58"}},{"content":"<strong>Agents with Action-Selection</strong>: Use mechanisms to choose from available actions.","children":[],"payload":{"tag":"li","lines":"58,59"}},{"content":"<strong>Utility-based Agents</strong>: Make decisions based on maximizing expected utility.","children":[],"payload":{"tag":"li","lines":"59,60"}},{"content":"<strong>Optimal Agents</strong>: Always choose the best action given perfect knowledge.","children":[],"payload":{"tag":"li","lines":"60,61"}},{"content":"<strong>Bounded Optimal Agents</strong>: Aim to act optimally within resource constraints.","children":[],"payload":{"tag":"li","lines":"61,63"}}],"payload":{"tag":"h4","lines":"54,55"}},{"content":"Brook&apos;s Reactive Architecture/Subsumption Architecture (~<code>Hungary Simple Creatures Like Overriding</code>)","children":[{"content":"Hierarchy of Task-Specific Behaviours","children":[],"payload":{"tag":"h5","lines":"64,65"}},{"content":"Each Behaviour is Simple and Rule Based","children":[],"payload":{"tag":"h5","lines":"65,66"}},{"content":"Behaviours Compete for Agent Control","children":[],"payload":{"tag":"h5","lines":"66,67"}},{"content":"Lower Layered Handle Urgent/Primitive Tasks","children":[],"payload":{"tag":"h5","lines":"67,68"}},{"content":"Lower Layers Override Higher Ones When Needed","children":[],"payload":{"tag":"h5","lines":"68,69"}}],"payload":{"tag":"h4","lines":"63,64"}},{"content":"Hybrid Architecture Subsystems","children":[{"content":"<strong>Deliberative Subsystem</strong>","children":[{"content":"Relies on a symbolic world model to handle planning and decision-making.","children":[],"payload":{"tag":"li","lines":"71,72"}}],"payload":{"tag":"h5","lines":"70,71"}},{"content":"<strong>Reactive Subsystem</strong>","children":[{"content":"Responds swiftly to events without engaging in complex reasoning or planning.","children":[],"payload":{"tag":"li","lines":"73,74"}}],"payload":{"tag":"h5","lines":"72,73"}},{"content":"3 Layering Possibilities (Horizontal, 1 Or 2 pass Vertical)","children":[],"payload":{"tag":"h5","lines":"74,75"}}],"payload":{"tag":"h4","lines":"69,70"}}],"payload":{"tag":"h3","lines":"45,46"}},{"content":"Agent Reasoning &amp; Commitment","children":[{"content":"\n<p data-lines=\"77,78\">Deductive Reasoning</p>","children":[{"content":"\n<p data-lines=\"78,79\"><strong>Approach</strong>:</p>","children":[{"content":"Uses <strong>logic and theorem proving</strong> to choose actions.","children":[],"payload":{"tag":"li","lines":"79,80"}},{"content":"Encodes a <strong>theory (&#x3c1;)</strong> that defines which actions are best in which situations.","children":[],"payload":{"tag":"li","lines":"80,82"}}],"payload":{"tag":"li","lines":"78,82"}},{"content":"\n<p data-lines=\"82,83\"><strong>Algorithm</strong>:</p>","children":[{"content":"1. Iterate through all possible actions: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>&#x3b1;</mi><mo>&#x2208;</mo><mtext>ValidActions</mtext></mrow><annotation encoding=\"application/x-tex\">\\alpha \\in \\text{ValidActions}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">&#x3b1;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&#x2208;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord text\"><span class=\"mord\">ValidActions</span></span></span></span></span>.","children":[],"payload":{"tag":"li","lines":"83,84","listIndex":1}},{"content":"2. For each action, check:","children":[{"content":"If <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>&#x3c1;</mi><mo>&#x22a2;</mo><mtext>Do</mtext><mo stretchy=\"false\">(</mo><mi>&#x3b1;</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\rho \\vdash \\text{Do}(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord mathnormal\">&#x3c1;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&#x22a2;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">Do</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">&#x3b1;</span><span class=\"mclose\">)</span></span></span></span> (i.e., it&apos;s provable that action &#x3b1; is the correct thing to do), or","children":[],"payload":{"tag":"li","lines":"85,86"}},{"content":"If <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"normal\">&#xac;</mi><mi>&#x3c1;</mi><mo>&#x22a2;</mo><mi mathvariant=\"normal\">&#xac;</mi><mtext>Do</mtext><mo stretchy=\"false\">(</mo><mi>&#x3b1;</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\neg \\rho \\vdash \\neg \\text{Do}(\\alpha)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord\">&#xac;</span><span class=\"mord mathnormal\">&#x3c1;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">&#x22a2;</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">&#xac;</span><span class=\"mord text\"><span class=\"mord\">Do</span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">&#x3b1;</span><span class=\"mclose\">)</span></span></span></span> (i.e., it is not provable that not doing &#x3b1; is better).","children":[],"payload":{"tag":"li","lines":"86,87"}}],"payload":{"tag":"li","lines":"84,87","listIndex":2}},{"content":"3. If so, <strong>return</strong> that action &#x3b1;.","children":[],"payload":{"tag":"li","lines":"87,88","listIndex":3}},{"content":"4. If no action satisfies this, return <strong>null</strong> (no action selected).","children":[],"payload":{"tag":"li","lines":"88,90","listIndex":4}}],"payload":{"tag":"li","lines":"82,90"}}],"payload":{"tag":"li","lines":"77,90"}},{"content":"\n<p data-lines=\"90,91\">Practical Reasoning &amp; Commitment Strategies (~ BOWSU)</p>","children":[{"content":"<strong>Essence</strong>","children":[{"content":"Focuses on deciding actions to achieve goals rather than managing beliefs.","children":[],"payload":{"tag":"li","lines":"92,93"}}],"payload":{"tag":"li","lines":"91,93"}},{"content":"<strong>Basic Algorithm</strong>","children":[{"content":"Continuously observes the world, updates its model, deliberates intentions, plans via means-ends reasoning, and executes the plan.","children":[],"payload":{"tag":"li","lines":"94,95"}}],"payload":{"tag":"li","lines":"93,95"}},{"content":"Commitment Strategies","children":[{"content":"Blind-commitment","children":[],"payload":{"tag":"li","lines":"96,97"}},{"content":"Over-commitment","children":[],"payload":{"tag":"li","lines":"97,98"}},{"content":"Wise Guy","children":[],"payload":{"tag":"li","lines":"98,99"}},{"content":"Single-minded Commitment","children":[],"payload":{"tag":"li","lines":"99,100"}},{"content":"Under-commitment","children":[],"payload":{"tag":"li","lines":"100,101"}}],"payload":{"tag":"li","lines":"95,101"}}],"payload":{"tag":"li","lines":"90,101"}}],"payload":{"tag":"h3","lines":"76,77"}}],"payload":{"tag":"h2","lines":"2,3"}},{"content":"Multi-Agent Systems","children":[{"content":"Developmental Drivers (~ <strong>UIIDH</strong>)","children":[{"content":"<strong>Ubiquity</strong>","children":[{"content":"Computing has become inexpensive and widespread, enabling its integration into many everyday devices.","children":[],"payload":{"tag":"li","lines":"104,105"}}],"payload":{"tag":"h4","lines":"103,104"}},{"content":"<strong>Interconnection</strong>","children":[{"content":"Systems are now networked, forming complex, interconnected environments.","children":[],"payload":{"tag":"li","lines":"106,107"}}],"payload":{"tag":"h4","lines":"105,106"}},{"content":"<strong>Intelligence</strong>","children":[{"content":"Computers can now automate increasingly complex tasks.","children":[],"payload":{"tag":"li","lines":"108,109"}}],"payload":{"tag":"h4","lines":"107,108"}},{"content":"<strong>Delegation</strong>","children":[{"content":"Machines act more autonomously, reducing the need for human intervention.","children":[],"payload":{"tag":"li","lines":"110,111"}}],"payload":{"tag":"h4","lines":"109,110"}},{"content":"<strong>Human Orientation</strong>","children":[{"content":"There is a shift toward designing systems that align with human thought processes rather than machine logic.","children":[],"payload":{"tag":"li","lines":"112,114"}}],"payload":{"tag":"h4","lines":"111,112"}}],"payload":{"tag":"h3","lines":"102,103"}},{"content":"Intent Management","children":[{"content":"Explore Intention Algorithm  <strong>SPiDeR - Start Pattern Distination Route End</strong>","children":[{"content":"<strong>Initial State</strong>","children":[{"content":"The agent begins exploring from its starting point with most of the map unknown.","children":[],"payload":{"tag":"li","lines":"117,118"}}],"payload":{"tag":"h5","lines":"116,117"}},{"content":"<strong>Exploration Pattern</strong>","children":[{"content":"It follows a spiral-like pattern by always targeting the nearest unknown location from its current or starting position, breaking ties randomly.","children":[],"payload":{"tag":"li","lines":"119,120"}}],"payload":{"tag":"h5","lines":"118,119"}},{"content":"<strong>Destination Selection</strong>","children":[{"content":"The destination is set slightly beyond the chosen unknown point to reveal new areas and support spiral expansion.","children":[],"payload":{"tag":"li","lines":"121,122"}}],"payload":{"tag":"h5","lines":"120,121"}},{"content":"<strong>Travel</strong>","children":[{"content":"The agent uses the Travel Intention to reach the selected destination.","children":[],"payload":{"tag":"li","lines":"123,124"}}],"payload":{"tag":"h5","lines":"122,123"}},{"content":"<strong>Termination</strong>","children":[{"content":"Exploration ends once the full map size is known and all locations have been di:scovered.","children":[],"payload":{"tag":"li","lines":"125,127"}}],"payload":{"tag":"h5","lines":"124,125"}}],"payload":{"tag":"h4","lines":"115,116"}},{"content":"Biding for Task Execution (<strong>BID LOW, GO!: Bid, Input, Decide</strong>)","children":[{"content":"<strong>Bid Content</strong>","children":[{"content":"Agents submit bids estimating the number of steps needed to complete a task, including any required role changes.","children":[],"payload":{"tag":"li","lines":"129,130"}}],"payload":{"tag":"h5","lines":"128,129"}},{"content":"<strong>Selection Criteria</strong>","children":[{"content":"The agent with the lowest step estimate is selected, ensuring the task is handled by the most efficient option.","children":[],"payload":{"tag":"li","lines":"131,132"}}],"payload":{"tag":"h5","lines":"130,131"}}],"payload":{"tag":"h4","lines":"127,128"}},{"content":"Task Achieving Intentions","children":[{"content":"Definitions of Intentions","children":[{"content":"Intentions guide agent behavior for task completion","children":[{"content":"are used exclusively by coordinators and block providers.","children":[],"payload":{"tag":"li","lines":"135,136"}}],"payload":{"tag":"li","lines":"134,136"}}],"payload":{"tag":"h5","lines":"133,134"}},{"content":"Types of Intentions (<strong>1A 3B 2C 2S</strong>)","children":[{"content":"<strong>Assemble</strong>","children":[{"content":"Allows the coordinator to receive a block from another agent.","children":[],"payload":{"tag":"li","lines":"138,139"}}],"payload":{"tag":"h6","lines":"137,138"}},{"content":"<strong>Block Collection</strong>","children":[{"content":"Instructs an agent to retrieve a specific type of block needed for a task.","children":[],"payload":{"tag":"li","lines":"140,141"}}],"payload":{"tag":"h6","lines":"139,140"}},{"content":"<strong>Block Delivery</strong>","children":[{"content":"Commands the agent to deliver a block to the coordinator.","children":[],"payload":{"tag":"li","lines":"142,143"}}],"payload":{"tag":"h6","lines":"141,142"}},{"content":"<strong>Block Providing</strong>","children":[{"content":"A core intention managing block scheduling, collection, and delivery.","children":[],"payload":{"tag":"li","lines":"144,145"}}],"payload":{"tag":"h6","lines":"143,144"}},{"content":"<strong>Connect</strong>","children":[{"content":"Directs an agent to hand over a block to another agent, typically the coordinator.","children":[],"payload":{"tag":"li","lines":"146,147"}}],"payload":{"tag":"h6","lines":"145,146"}},{"content":"<strong>Coordination</strong>","children":[{"content":"The main intention for overseeing and completing the task submission process.","children":[],"payload":{"tag":"li","lines":"148,149"}}],"payload":{"tag":"h6","lines":"147,148"}},{"content":"<strong>Single Block Submission</strong>","children":[{"content":"Involves delivering and submitting a single block to a goal zone.","children":[],"payload":{"tag":"li","lines":"150,151"}}],"payload":{"tag":"h6","lines":"149,150"}},{"content":"<strong>Single Block Providing</strong>","children":[{"content":"Merges block collection and coordination for single-task flows","children":[],"payload":{"tag":"li","lines":"152,154"}}],"payload":{"tag":"h6","lines":"151,152"}}],"payload":{"tag":"h5","lines":"136,137"}},{"content":"Task Option Generation &amp; Filtering (<strong>TOP F: Tasks every tick, Only if ready, Per map, Filter by fit</strong>)","children":[{"content":"<strong>Task Option Generation</strong>","children":[{"content":"Tasks are generated at every simulation step, independently of agent actions or resource reservations.","children":[],"payload":{"tag":"li","lines":"156,157"}}],"payload":{"tag":"h6","lines":"155,156"}},{"content":"<strong>Conditions</strong>","children":[{"content":"A task becomes an option only if its prerequisites are met.","children":[],"payload":{"tag":"li","lines":"158,159"}}],"payload":{"tag":"h6","lines":"157,158"}},{"content":"<strong>Per-Map Basis</strong>","children":[{"content":"Task generation occurs separately for each dynamic map.","children":[],"payload":{"tag":"li","lines":"160,161"}}],"payload":{"tag":"h6","lines":"159,160"}},{"content":"<strong>Filtering Parameters</strong>","children":[{"content":"Generated tasks are filtered based on the availability of goal zones, agents, and role zones, keeping only those that match current resources.","children":[],"payload":{"tag":"li","lines":"162,163"}}],"payload":{"tag":"h6","lines":"161,162"}}],"payload":{"tag":"h5","lines":"154,155"}}],"payload":{"tag":"h4","lines":"132,133"}}],"payload":{"tag":"h3","lines":"114,115"}},{"content":"Path Finding","children":[{"content":"Path Finder <strong>(AIDF - A* Modified, Iteration Limit, Distance Eculidean, First step only)</strong>","children":[{"content":"<strong>Algorithm Base</strong>","children":[{"content":"Built on a modified A* algorithm.","children":[],"payload":{"tag":"li","lines":"166,167"}}],"payload":{"tag":"h5","lines":"165,166"}},{"content":"<strong>Heuristic</strong>","children":[{"content":"Uses Euclidean distance to estimate the cost to the destination.","children":[],"payload":{"tag":"li","lines":"168,169"}}],"payload":{"tag":"h5","lines":"167,168"}},{"content":"<strong>Time Constraint</strong>","children":[{"content":"Pathfinding is capped by a fixed iteration limit; if the goal isn&apos;t reached, the closest node becomes the endpoint.","children":[],"payload":{"tag":"li","lines":"170,171"}}],"payload":{"tag":"h5","lines":"169,170"}},{"content":"<strong>Dynamic Adaptation</strong>","children":[{"content":"Only the first step of the path is reliably used, as frequent environment changes can invalidate the rest.","children":[],"payload":{"tag":"li","lines":"172,173"}}],"payload":{"tag":"h5","lines":"171,172"}}],"payload":{"tag":"h4","lines":"164,165"}},{"content":"Cooperative A* <strong>(TIPS, Time-tagged cells, In order, Priority-based reservations, Space-time A*)</strong>","children":[{"content":"<strong>Extension of A*</strong>","children":[{"content":"Adapts A* to support multi-agent collision avoidance by adding time as a third dimension.","children":[],"payload":{"tag":"li","lines":"175,176"}}],"payload":{"tag":"h5","lines":"174,175"}},{"content":"<strong>Time Dimension</strong>","children":[{"content":"Each cell is marked with the time an agent will occupy it.","children":[],"payload":{"tag":"li","lines":"177,178"}}],"payload":{"tag":"h5","lines":"176,177"}},{"content":"<strong>Sequential Planning</strong>","children":[{"content":"Agents plan in priority order, reserving timed cells which later agents treat as moving obstacles.","children":[],"payload":{"tag":"li","lines":"179,180"}}],"payload":{"tag":"h5","lines":"178,179"}},{"content":"<strong>Collision Avoidance</strong>","children":[{"content":"A* is run in space-time, preventing both spatial and temporal conflicts between agents.","children":[],"payload":{"tag":"li","lines":"181,182"}}],"payload":{"tag":"h5","lines":"180,181"}}],"payload":{"tag":"h4","lines":"173,174"}},{"content":"Cooperative A* with Lifelong Multi-Agent Pathfinding <strong>(NO replan, Newbies stuck, Old paths frozen)</strong>","children":[{"content":"Definition","children":[{"content":"Continuously Assigning new Tasks to Agents over time.","children":[],"payload":{"tag":"li","lines":"184,185"}}],"payload":{"tag":"h5","lines":"183,184"}},{"content":"Problem1: Lack of Dynamic Planning:","children":[{"content":"Once paths are reserved, agents don&apos;t adapt to changes, leading to suboptimal or blocked paths.","children":[],"payload":{"tag":"li","lines":"186,187"}}],"payload":{"tag":"h5","lines":"185,186"}},{"content":"Problem2: New Agents Get Stuck","children":[{"content":"Unable to reroute or negotiate around existing reservations.","children":[],"payload":{"tag":"li","lines":"188,189"}}],"payload":{"tag":"h5","lines":"187,188"}}],"payload":{"tag":"h4","lines":"182,183"}},{"content":"PIBT (Priority Inheritance with Backtracking)","children":[{"content":"Overview <strong>(HELP, Higher-rank shared, Each timestep counts, Locked in loops: Problem Deadlock)</strong>","children":[{"content":"<strong>PIBT</strong>","children":[{"content":"Stands for Priority Inheritance with Backtracking.","children":[],"payload":{"tag":"li","lines":"192,193"}}],"payload":{"tag":"h6","lines":"191,192"}},{"content":"<strong>Priority Inheritance</strong>","children":[{"content":"Lets lower-priority agents temporarily adopt higher-priority ones&#x2019; priorities to enable their movement.","children":[],"payload":{"tag":"li","lines":"194,195"}}],"payload":{"tag":"h6","lines":"193,194"}},{"content":"<strong>Step-by-step Operation</strong>","children":[{"content":"At each timestep, agents update priorities and, in descending order, select a move while avoiding cells requested by higher-priority agents.","children":[],"payload":{"tag":"li","lines":"196,197"}}],"payload":{"tag":"h6","lines":"195,196"}},{"content":"<strong>Deadlock Possibility</strong>","children":[{"content":"Cyclic priority inheritance can cause deadlock when the last agent in the chain has no valid move options.","children":[],"payload":{"tag":"li","lines":"198,200"}}],"payload":{"tag":"h6","lines":"197,198"}}],"payload":{"tag":"h5","lines":"190,191"}},{"content":"Backtracking Solution <strong>(BACK: Block check, avoid nodes, Chain returns, Kickstart again)</strong>","children":[{"content":"<strong>Validation Check</strong>","children":[{"content":"After inheriting priority, an agent waits to confirm if its move is valid; if not, it must select another node.","children":[],"payload":{"tag":"li","lines":"202,203"}}],"payload":{"tag":"h6","lines":"201,202"}},{"content":"<strong>Exclusion Rules</strong>","children":[{"content":"Agents avoid nodes already claimed by higher-priority agents or previously resulting in invalid outcomes.","children":[],"payload":{"tag":"li","lines":"204,205"}}],"payload":{"tag":"h6","lines":"203,204"}},{"content":"<strong>Backtracking Chain</strong>","children":[{"content":"If no valid moves remain, the agent returns an invalid outcome to the one that passed it priority.","children":[],"payload":{"tag":"li","lines":"206,207"}}],"payload":{"tag":"h6","lines":"205,206"}},{"content":"<strong>Example Resolution</strong>","children":[{"content":"In a blocked chain, agents backtrack step-by-step until one finds a valid move, allowing others to follow and resolve the deadlock.","children":[],"payload":{"tag":"li","lines":"208,209"}},{"content":"<img src=\"attachments/Pastedimage20250626175849.png\" alt>","children":[],"payload":{"tag":"li","lines":"209,211"}}],"payload":{"tag":"h6","lines":"207,208"}}],"payload":{"tag":"h5","lines":"200,201"}}],"payload":{"tag":"h4","lines":"189,190"}}],"payload":{"tag":"h3","lines":"163,164"}},{"content":"Perception &amp; Environment Mapping","children":[{"content":"Agent Identification","children":[{"content":"<strong>Detection</strong>","children":[{"content":"An agent attempts to identify another agent when it spots one nearby.","children":[],"payload":{"tag":"li","lines":"214,215"}}],"payload":{"tag":"h5","lines":"213,214"}},{"content":"<strong>Inquiry</strong>","children":[{"content":"It asks all agents if they see someone in the mirrored position, based on relative distance and direction.","children":[],"payload":{"tag":"li","lines":"216,217"}}],"payload":{"tag":"h5","lines":"215,216"}},{"content":"<strong>Matching</strong>","children":[{"content":"Agents compare shared visible landmarks or obstacles to eliminate unlikely identities.","children":[],"payload":{"tag":"li","lines":"218,219"}}],"payload":{"tag":"h5","lines":"217,218"}},{"content":"<strong>Success</strong>","children":[{"content":"Identification succeeds if only one matching candidate is found.","children":[],"payload":{"tag":"li","lines":"220,221"}}],"payload":{"tag":"h5","lines":"219,220"}},{"content":"<strong>Failure</strong>","children":[{"content":"The process fails if no unique match is identified.","children":[],"payload":{"tag":"li","lines":"222,224"}}],"payload":{"tag":"h5","lines":"221,222"}}],"payload":{"tag":"h4","lines":"212,213"}},{"content":"Map Merging","children":[{"content":"<strong>Pairwise Merging</strong>","children":[{"content":"Maps are merged two at a time, though several such merges can occur in a single time step.","children":[],"payload":{"tag":"li","lines":"226,227"}}],"payload":{"tag":"h5","lines":"225,226"}},{"content":"<strong>Coordinate System</strong>","children":[{"content":"One agent&#x2019;s coordinate system remains fixed while the other&#x2019;s is adjusted to align.","children":[],"payload":{"tag":"li","lines":"228,229"}}],"payload":{"tag":"h5","lines":"227,228"}},{"content":"<strong>Map Integration</strong>","children":[{"content":"Unique elements are added directly, while shared elements are resolved by keeping the most recent data.","children":[],"payload":{"tag":"li","lines":"230,232"}}],"payload":{"tag":"h5","lines":"229,230"}}],"payload":{"tag":"h4","lines":"224,225"}},{"content":"Map Size Discovery","children":[{"content":"<strong>Looping World</strong>","children":[{"content":"The map wraps around, allowing agents to move endlessly without encountering visible edges.","children":[],"payload":{"tag":"li","lines":"234,235"}}],"payload":{"tag":"h5","lines":"233,234"}},{"content":"<strong>Map Size Discovery</strong>","children":[{"content":"If two agents report the same object at different coordinates during map merging, it indicates the map loops.","children":[],"payload":{"tag":"li","lines":"236,237"}}],"payload":{"tag":"h5","lines":"235,236"}},{"content":"<strong>Size Calculation</strong>","children":[{"content":"The map size is computed using the difference in reported coordinates plus relative distance, revealing its full width or height.    <p class=\"katex-block\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mtext>Map&#xa0;size</mtext><mo>=</mo><mi mathvariant=\"normal\">&#x2223;</mi><msub><mtext>coordinate</mtext><mn>1</mn></msub><mo>&#x2212;</mo><msub><mtext>coordinate</mtext><mn>2</mn></msub><mo>+</mo><mtext>relative&#xa0;distance</mtext><mi mathvariant=\"normal\">&#x2223;</mi></mrow><annotation encoding=\"application/x-tex\">    \\text{Map size} = |\\text{coordinate}_1 - \\text{coordinate}_2 + \\text{relative distance}|    </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Map&#xa0;size</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">&#x2223;</span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">coordinate</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">&#x2212;</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord text\"><span class=\"mord\">coordinate</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">relative&#xa0;distance</span></span><span class=\"mord\">&#x2223;</span></span></span></span></span></p>","children":[],"payload":{"tag":"li","lines":"238,240"}}],"payload":{"tag":"h5","lines":"237,238"}}],"payload":{"tag":"h4","lines":"232,233"}}],"payload":{"tag":"h3","lines":"211,212"}},{"content":"Coordination &amp; Cooperation","children":[{"content":"FIPA Agent Platform Components","children":[{"content":"<img src=\"attachments/Pastedimage20250626175909.png\" alt>","children":[],"payload":{"tag":"li","lines":"242,243"}},{"content":"AMS (Agent Management System)","children":[],"payload":{"tag":"li","lines":"243,244"}},{"content":"ACC (Agent Communication Channel)","children":[],"payload":{"tag":"li","lines":"244,245"}},{"content":"DF (Directory Facilitator) Providing Yellow-Pages Service for Agents","children":[],"payload":{"tag":"li","lines":"245,246"}}],"payload":{"tag":"h4","lines":"241,242"}},{"content":"Cooperative Distributed Problem Solving","children":[{"content":"<strong>Problem Decomposition</strong>","children":[{"content":"The main problem is divided into smaller, manageable sub-problems.","children":[],"payload":{"tag":"li","lines":"248,249"}}],"payload":{"tag":"h5","lines":"247,248"}},{"content":"<strong>Subproblem Distribution</strong>","children":[{"content":"Each sub-problem is assigned to an agent best suited to solve it.","children":[],"payload":{"tag":"li","lines":"250,251"}}],"payload":{"tag":"h5","lines":"249,250"}},{"content":"<strong>Subproblem Solution</strong>","children":[{"content":"Agents work independently to solve their respective sub-problems.","children":[],"payload":{"tag":"li","lines":"252,253"}}],"payload":{"tag":"h5","lines":"251,252"}},{"content":"<strong>Answer Synthesis</strong>","children":[{"content":"All individual solutions are combined to form a complete solution to the original problem.","children":[],"payload":{"tag":"li","lines":"254,256"}}],"payload":{"tag":"h5","lines":"253,254"}}],"payload":{"tag":"h4","lines":"246,247"}},{"content":"Joint Intention Termination","children":[{"content":"A joint intention is removed when an agent believes it has succeeded, become impossible, or unachievable","children":[],"payload":{"tag":"h5","lines":"257,258"}},{"content":"Then the agent forms a new intention to ensure all agents share this belief before the joint intention is officially dropped","children":[],"payload":{"tag":"h5","lines":"258,259"}}],"payload":{"tag":"h4","lines":"256,257"}},{"content":"Speech Act Message","children":[{"content":"<strong>Performative Verb</strong>","children":[{"content":"Specifies the type of communication act, such as a request or an inform.","children":[],"payload":{"tag":"li","lines":"261,262"}}],"payload":{"tag":"h5","lines":"260,261"}},{"content":"<strong>Propositional Content</strong>","children":[{"content":"Represents the actual message or information being communicated.","children":[],"payload":{"tag":"li","lines":"263,264"}}],"payload":{"tag":"h5","lines":"262,263"}},{"content":"<strong>Example</strong>","children":[{"content":"In &quot;Please close the door!&quot;, the performative is <code>request</code> and the propositional content is <code>the door is closed</code>.","children":[],"payload":{"tag":"li","lines":"265,267"}}],"payload":{"tag":"h5","lines":"264,265"}}],"payload":{"tag":"h4","lines":"259,260"}}],"payload":{"tag":"h3","lines":"240,241"}},{"content":"Game Theory Models","children":[{"content":"Equilibrium Conditions in Routing Games &amp; Price of Anarchy","children":[{"content":"<strong>Non-Atomic Routing Games</strong>","children":[{"content":"Always have an equilibrium, with a Price of Anarchy (PoA) upper bound of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>4</mn><mn>3</mn></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{4}{3}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">3</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">4</span></span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> for affine cost functions.","children":[],"payload":{"tag":"li","lines":"270,271"}}],"payload":{"tag":"h5","lines":"269,270"}},{"content":"<strong>Atomic Routing Games</strong>","children":[{"content":"Equilibrium exists if traffic units are equal or costs are affine, with PoA bounds of <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mfrac><mn>5</mn><mn>2</mn></mfrac></mrow><annotation encoding=\"application/x-tex\">\\frac{5}{2}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.1901em;vertical-align:-0.345em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8451em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">5</span></span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.345em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span> for equal units and approximately 2.618 for affine costs.","children":[],"payload":{"tag":"li","lines":"272,274"}}],"payload":{"tag":"h5","lines":"271,272"}}],"payload":{"tag":"h4","lines":"268,269"}},{"content":"Nash Equilibrium","children":[{"content":"A pair of strategies is in Nash Equilibrium if neither agent can benefit by changing their strategy alone, as each is the best response to the other.","children":[],"payload":{"tag":"li","lines":"275,276"}},{"content":"<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mo>=</mo><mtext>BestResponse</mtext><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mn>2</mn></msub><mo stretchy=\"false\">)</mo><mo separator=\"true\">,</mo><mspace width=\"1em\"/><msub><mi>s</mi><mn>2</mn></msub><mo>=</mo><mtext>BestResponse</mtext><mo stretchy=\"false\">(</mo><msub><mi>s</mi><mn>1</mn></msub><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">s_1 = \\text{BestResponse}(s_2), \\quad s_2 = \\text{BestResponse}(s_1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5806em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">BestResponse</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">2</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord text\"><span class=\"mord\">BestResponse</span></span><span class=\"mopen\">(</span><span class=\"mord\"><span class=\"mord mathnormal\">s</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3011em;\"><span style=\"top:-2.55em;margin-left:0em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"tag":"li","lines":"276,277"}}],"payload":{"tag":"h4","lines":"274,275"}},{"content":"Dynamic Shortest Path &amp; Dynamic Equilibrium","children":[{"content":"<strong>Dynamic Shortest Path</strong>","children":[{"content":"A particle starting at time &#x3b8;\\theta follows a path that minimizes its arrival time at the destination, accounting for time-dependent edge delays.  <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>T</mi><mi>p</mi></msub><mo stretchy=\"false\">(</mo><mi>&#x3b8;</mi><mo stretchy=\"false\">)</mo><mo>=</mo><msub><mi>T</mi><msub><mi>e</mi><mi>k</mi></msub></msub><mo>&#x2218;</mo><mo>&#x22ef;</mo><mo>&#x2218;</mo><msub><mi>T</mi><msub><mi>e</mi><mn>1</mn></msub></msub><mo stretchy=\"false\">(</mo><mi>&#x3b8;</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">T_p(\\theta) = T_{e_k} \\circ \\dots \\circ T_{e_1}(\\theta)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.0361em;vertical-align:-0.2861em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">p</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2861em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">&#x3b8;</span><span class=\"mclose\">)</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.9392em;vertical-align:-0.2559em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3488em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1512em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2559em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">&#x2218;</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.4445em;\"></span><span class=\"minner\">&#x22ef;</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">&#x2218;</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.0001em;vertical-align:-0.2501em;\"></span><span class=\"mord\"><span class=\"mord mathnormal\" style=\"margin-right:0.13889em;\">T</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.1389em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathnormal mtight\">e</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3173em;\"><span style=\"top:-2.357em;margin-left:0em;margin-right:0.0714em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\">1</span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.143em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">&#x200b;</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2501em;\"><span></span></span></span></span></span></span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02778em;\">&#x3b8;</span><span class=\"mclose\">)</span></span></span></span>","children":[],"payload":{"tag":"li","lines":"279,280"}}],"payload":{"tag":"h5","lines":"278,279"}},{"content":"<strong>Dynamic Equilibrium</strong>","children":[{"content":"A routing state where all agents use their dynamic shortest paths, with no incentive to switch routes, ensuring stability given current traffic conditions.","children":[],"payload":{"tag":"li","lines":"281,282"}}],"payload":{"tag":"h5","lines":"280,281"}}],"payload":{"tag":"h4","lines":"277,278"}},{"content":"Sum, Hicks and Pareto Optimality","children":[{"content":"<strong>Sum Optimality</strong>","children":[{"content":"Maximizes the total utility of all agents, focusing solely on overall outcome efficiency.","children":[],"payload":{"tag":"li","lines":"284,285"}}],"payload":{"tag":"h5","lines":"283,284"}},{"content":"<strong>Hicks Optimality</strong>","children":[{"content":"A state where winners could compensate losers and still benefit, emphasizing theoretical fairness.","children":[],"payload":{"tag":"li","lines":"286,287"}}],"payload":{"tag":"h5","lines":"285,286"}},{"content":"<strong>Pareto Optimality</strong>","children":[{"content":"No one can be better off without making someone else worse off, ensuring efficient outcomes without waste.","children":[],"payload":{"tag":"li","lines":"288,289"}}],"payload":{"tag":"h5","lines":"287,288"}},{"content":"<strong>Is Pareto Optimal an Equilibrium?</strong>","children":[{"content":"Not always&#x2014;Pareto optimality doesn&#x2019;t ensure stability, as agents may still have incentives to deviate.","children":[],"payload":{"tag":"li","lines":"290,291"}}],"payload":{"tag":"h5","lines":"289,290"}},{"content":"<strong>Example</strong>","children":[{"content":"A payoff of (4,4) is Pareto optimal, but Agent 1 might prefer (5,3) for personal gain, even at Agent 2&#x2019;s expense.","children":[],"payload":{"tag":"li","lines":"292,293"}}],"payload":{"tag":"h5","lines":"291,292"}}],"payload":{"tag":"h4","lines":"282,283"}},{"content":"Prisoner&apos;s Dilemma","children":[{"content":"<strong>Problem</strong>","children":[{"content":"Cooperation breaks down among self-interested agents.","children":[],"payload":{"tag":"li","lines":"295,296"}}],"payload":{"tag":"h5","lines":"294,295"}},{"content":"<strong>Cause</strong>","children":[{"content":"Agents act on individual rationality, choosing to defect even when cooperation yields better overall outcomes.","children":[],"payload":{"tag":"li","lines":"297,298"}}],"payload":{"tag":"h5","lines":"296,297"}},{"content":"<strong>Correct Strategy</strong>","children":[{"content":"Always defect in every round.","children":[],"payload":{"tag":"li","lines":"299,300"}}],"payload":{"tag":"h5","lines":"298,299"}},{"content":"<strong>Justification</strong>","children":[{"content":"Backward induction shows rational agents will defect in the final round and, anticipating this, defect in every previous round as well.","children":[],"payload":{"tag":"li","lines":"301,302"}}],"payload":{"tag":"h5","lines":"300,301"}},{"content":"<strong>When This Fails</strong>","children":[{"content":"If the number of rounds is unknown, infinite, or not predetermined, agents may cooperate to preserve future benefits.","children":[],"payload":{"tag":"li","lines":"303,305"}}],"payload":{"tag":"h5","lines":"302,303"}}],"payload":{"tag":"h4","lines":"293,294"}}],"payload":{"tag":"h3","lines":"267,268"}},{"content":"Agreements","children":[{"content":"<strong>Strategy</strong>","children":[{"content":"The decision-making plan an agent follows, based on its private knowledge and assumptions about others.","children":[],"payload":{"tag":"li","lines":"307,308"}}],"payload":{"tag":"h4","lines":"306,307"}},{"content":"<strong>Mechanism</strong>","children":[{"content":"A protocol outlining the rules and structure of agent interactions.","children":[],"payload":{"tag":"li","lines":"309,310"}}],"payload":{"tag":"h4","lines":"308,309"}},{"content":"<strong>Negotiation Set</strong>","children":[{"content":"The complete set of proposals that agents can potentially offer.","children":[],"payload":{"tag":"li","lines":"311,312"}}],"payload":{"tag":"h4","lines":"310,311"}},{"content":"<strong>Termination Rule</strong>","children":[{"content":"Specifies the conditions under which negotiation concludes and a deal is finalized.","children":[],"payload":{"tag":"li","lines":"313,314"}}],"payload":{"tag":"h4","lines":"312,313"}},{"content":"<strong>Mechanism Design</strong>","children":[{"content":"The process of crafting mechanisms to achieve specific desired outcomes.","children":[],"payload":{"tag":"li","lines":"315,316"}}],"payload":{"tag":"h4","lines":"314,315"}},{"content":"<strong>Mechanism Design Properties</strong>","children":[{"content":"<strong>Stability</strong>","children":[{"content":"No agent has an incentive to deviate from the agreed solution.","children":[],"payload":{"tag":"li","lines":"318,319"}}],"payload":{"tag":"h5","lines":"317,318"}},{"content":"<strong>Convergence</strong>","children":[{"content":"Ensures the negotiation will reach a definite conclusion.","children":[],"payload":{"tag":"li","lines":"320,321"}}],"payload":{"tag":"h5","lines":"319,320"}},{"content":"<strong>Individual Rationality</strong>","children":[{"content":"Participation is beneficial for each agent compared to opting out.","children":[],"payload":{"tag":"li","lines":"322,323"}}],"payload":{"tag":"h5","lines":"321,322"}},{"content":"<strong>Pareto Efficiency</strong>","children":[{"content":"Guarantees no agent can be better off without disadvantaging another.","children":[],"payload":{"tag":"li","lines":"324,325"}}],"payload":{"tag":"h5","lines":"323,324"}},{"content":"<strong>Maximizing Social Welfare</strong>","children":[{"content":"The outcome maximizes the overall benefit for all agents involved.","children":[],"payload":{"tag":"li","lines":"326,328"}}],"payload":{"tag":"h5","lines":"325,326"}}],"payload":{"tag":"h4","lines":"316,317"}},{"content":"Negotiation Types","children":[{"content":"<strong>Task Oriented</strong>","children":[{"content":"Agents negotiate to allocate indivisible tasks with associated costs in a way that minimizes individual burdens through fair or efficient redistribution.","children":[],"payload":{"tag":"li","lines":"330,331"}},{"content":"Deception Possibilities","children":[{"content":"<strong>Phantom/Decoy Tasks</strong>","children":[{"content":"Agents fake tasks to mislead others and appear busier, distorting negotiation outcomes.","children":[],"payload":{"tag":"li","lines":"333,334"}}],"payload":{"tag":"li","lines":"332,334"}},{"content":"<strong>Hidden Tasks</strong>","children":[{"content":"Agents hide real tasks to seem less loaded, manipulating task allocation in their favor.","children":[],"payload":{"tag":"li","lines":"335,337"}}],"payload":{"tag":"li","lines":"334,337"}}],"payload":{"tag":"li","lines":"331,337"}}],"payload":{"tag":"h5","lines":"329,330"}},{"content":"<strong>State Oriented</strong>","children":[{"content":"Agents negotiate to create a joint plan and schedule that leads to a mutually acceptable final world state, considering the side-effects of their actions.","children":[],"payload":{"tag":"li","lines":"338,339"}}],"payload":{"tag":"h5","lines":"337,338"}},{"content":"<strong>Worth Oriented</strong>","children":[{"content":"Based on <strong>maximizing collective value or worth</strong>.","children":[],"payload":{"tag":"li","lines":"340,341"}}],"payload":{"tag":"h5","lines":"339,340"}}],"payload":{"tag":"h4","lines":"328,329"}},{"content":"Auction","children":[{"content":"<strong>English Auction</strong>","children":[{"content":"Bidders openly raise their offers, and the highest bidder wins by paying their bid amount; it&apos;s an open auction.","children":[],"payload":{"tag":"li","lines":"343,344"}}],"payload":{"tag":"h5","lines":"342,343"}},{"content":"<strong>Dutch Auction</strong>","children":[{"content":"The auctioneer lowers the price until someone accepts, with the first to accept winning and paying the current price; it&apos;s open.","children":[],"payload":{"tag":"li","lines":"345,346"}}],"payload":{"tag":"h5","lines":"344,345"}},{"content":"<strong>Vickrey Auction</strong>","children":[{"content":"Bidders submit sealed bids privately, the highest bidder wins but pays the second-highest bid; it&apos;s a closed auction and aligns with the Generalized Second Price model used online.","children":[],"payload":{"tag":"li","lines":"347,348"}}],"payload":{"tag":"h5","lines":"346,347"}},{"content":"<strong>First-Price Sealed Bid</strong>","children":[{"content":"One bid submitted secretly; highest wins.","children":[],"payload":{"tag":"li","lines":"349,350"}}],"payload":{"tag":"h5","lines":"348,349"}}],"payload":{"tag":"h4","lines":"341,342"}},{"content":"Contract Net Protocol Phases","children":[{"content":"<strong>Recognition</strong>","children":[{"content":"An agent realizes it needs assistance to complete a task.","children":[],"payload":{"tag":"li","lines":"352,353"}}],"payload":{"tag":"h5","lines":"351,352"}},{"content":"<strong>Announcement</strong>","children":[{"content":"The agent broadcasts task details to potential helpers.","children":[],"payload":{"tag":"li","lines":"354,355"}}],"payload":{"tag":"h5","lines":"353,354"}},{"content":"<strong>Bidding</strong>","children":[{"content":"Other agents submit bids based on their capability or interest.","children":[],"payload":{"tag":"li","lines":"356,357"}}],"payload":{"tag":"h5","lines":"355,356"}},{"content":"<strong>Awarding</strong>","children":[{"content":"The task is assigned to the most suitable bidder.","children":[],"payload":{"tag":"li","lines":"358,359"}}],"payload":{"tag":"h5","lines":"357,358"}},{"content":"<strong>Expediting</strong>","children":[{"content":"The chosen agent performs the task and may delegate parts if needed.","children":[],"payload":{"tag":"li","lines":"360,361"}}],"payload":{"tag":"h5","lines":"359,360"}},{"content":"<strong>Why it&apos;s a Natural Extension</strong>","children":[{"content":"It evolves centralized control into dynamic, decentralized task allocation via negotiation.","children":[],"payload":{"tag":"li","lines":"362,363"}}],"payload":{"tag":"h5","lines":"361,362"}}],"payload":{"tag":"h4","lines":"350,351"}}],"payload":{"tag":"h3","lines":"305,306"}}],"payload":{"tag":"h2","lines":"101,102"}}],"payload":{"tag":"h1","lines":"1,2"}},{})</script>
</body>
</html>
